{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_-_-_-_-_- Model Construction using Ridge Regression _-_-_-_-_-\n",
      "\n",
      "Loading Data ...\n",
      "\n",
      "Cleaning Data ...\n",
      "\n",
      "------ Computing weights for batch 0 -------\n",
      "\n",
      "Calculating best degree and lambda :\n",
      "Best degree = 7\n",
      "Best lambda = 1e-07\n",
      "\n",
      "Predicting labels ...\n",
      "------ Computing weights for batch 1 -------\n",
      "\n",
      "Calculating best degree and lambda :\n",
      "Best degree = 6\n",
      "Best lambda = 1e-07\n",
      "\n",
      "Predicting labels ...\n",
      "------ Computing weights for batch 2 -------\n",
      "\n",
      "Calculating best degree and lambda :\n",
      "Best degree = 7\n",
      "Best lambda = 1e-05\n",
      "\n",
      "Predicting labels ...\n",
      "------ Computing weights for batch 3 -------\n",
      "\n",
      "Calculating best degree and lambda :\n",
      "Best degree = 7\n",
      "Best lambda = 1e-05\n",
      "\n",
      "Predicting labels ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from clean_data import clean_data\n",
    "from visualize_features import visualize_features\n",
    "from cross_validation import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    " #####################################################\n",
    "\n",
    "submission = True\n",
    "train_ratio = 0.7\n",
    "seed = 1\n",
    "\n",
    "print(\"_-_-_-_-_- Model Construction using Ridge Regression _-_-_-_-_-\\n\")\n",
    "\n",
    "print(\"Loading Data ...\\n\")\n",
    "# Load Data\n",
    "path_dataset_train = \"train.csv\"\n",
    "yb, input_data, ids = load_csv_data(path_dataset_train)\n",
    "\n",
    "path_dataset_test = \"test.csv\"\n",
    "yb_t, input_data_t, ids_t = load_csv_data(path_dataset_test)\n",
    "\n",
    " #####################################################\n",
    "print(\"Cleaning Data ...\\n\")\n",
    "    \n",
    "# Data Cleaning\n",
    "batches = clean_data(input_data,yb,ids)\n",
    "batches_test = clean_data(input_data_t,yb_t,ids_t, test=True) #Doesn't delete data points (only filters features\\\n",
    "\n",
    " #####################################################\n",
    "\n",
    "\n",
    "if (submission):\n",
    "    y_pred_sub = np.zeros(len(ids_t))\n",
    "else :\n",
    "    score = 0;\n",
    "\n",
    "i = 0;\n",
    "for [tx, y, ids],[tx_test,y_test,ids_test] in zip(batches,batches_test) :\n",
    "    \n",
    "    print(\"------ Computing weights for batch {} -------\\n\".format(i))\n",
    "    \n",
    "             #### Feature Visualization (uncomment to test) ####\n",
    "        \n",
    "    # features = np.array([1,4,5]) # Features to compare\n",
    "    # visualize_features(tx0,y0,features,'Feature_comparision')\n",
    "    \n",
    "    if (not(submission)) : # We overwrite the test data\n",
    "        tx_train, y_train, tx_test, y_test, ids_train, ids_test = split_data(tx, y, ids, train_ratio, seed=1)\n",
    "    else :\n",
    "        y_train = y\n",
    "        tx_train = tx\n",
    "        ids_train = ids\n",
    "    \n",
    "    print(\"Calculating best degree and lambda :\")\n",
    "    \n",
    "    degree = best_degree(y_train, tx_train, 0)\n",
    "    print(\"Best degree = {}\".format(degree))\n",
    "    \n",
    "    lambda_ = best_lambda(y_train, tx_train, degree)\n",
    "    print(\"Best lambda = {}\\n\".format(lambda_))\n",
    "    \n",
    "    \n",
    "    tx_poly_train = build_poly_f(tx_train, degree)\n",
    "    \n",
    "    _, w = ridge_regression(y_train, tx_poly_train, lambda_)\n",
    "    \n",
    "    tx_poly_test = build_poly_f(tx_test, degree)\n",
    "    \n",
    "    print(\"Predicting labels ...\")\n",
    "    \n",
    "    y_pred = predict_labels(w,tx_poly_test)\n",
    "    \n",
    "    if (submission):\n",
    "        y_pred_sub[ids_test-ids_t[0]] = y_pred\n",
    "    else :\n",
    "        score_aux = find_score(y_pred,y_test)\n",
    "        score += score_aux/4.\n",
    "        \n",
    "        print(\"Score for batch {} = {} \\n\".format(i,score_aux))\n",
    "\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "if (submission):\n",
    "    create_csv_submission(ids_t, y_pred_sub, 'submission.csv')\n",
    "else :\n",
    "    print(\"Final score = {} \\n\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "_-_-_-_-_- Model Construction using Logistic Regression _-_-_-_-_-\n",
      "\n",
      "Loading Data ...\n",
      "\n",
      "Cleaning Data ...\n",
      "\n",
      "------ Computing weights for batch 0 -------\n",
      "\n",
      "Predicting labels ...\n",
      "------ Computing weights for batch 1 -------\n",
      "\n",
      "Predicting labels ...\n",
      "------ Computing weights for batch 2 -------\n",
      "\n",
      "Predicting labels ...\n",
      "------ Computing weights for batch 3 -------\n",
      "\n",
      "Predicting labels ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from clean_data import clean_data\n",
    "from visualize_features import visualize_features\n",
    "from cross_validation import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    " #####################################################\n",
    "\n",
    "submission = True\n",
    "train_ratio = 0.7\n",
    "seed = 1\n",
    "\n",
    "max_iters = 200\n",
    "gamma = 0.00001\n",
    "degree = 2\n",
    "\n",
    "print(\"_-_-_-_-_- Model Construction using Logistic Regression _-_-_-_-_-\\n\")\n",
    "\n",
    "print(\"Loading Data ...\\n\")\n",
    "# Load Data\n",
    "path_dataset_train = \"train.csv\"\n",
    "yb, input_data, ids = load_csv_data(path_dataset_train)\n",
    "\n",
    "path_dataset_test = \"test.csv\"\n",
    "yb_t, input_data_t, ids_t = load_csv_data(path_dataset_test)\n",
    "\n",
    "yb[np.where(yb == -1)] = 0\n",
    "yb_t[np.where(yb_t == -1)] = 0\n",
    "\n",
    " #####################################################\n",
    "print(\"Cleaning Data ...\\n\")\n",
    "    \n",
    "# Data Cleaning\n",
    "batches = clean_data(input_data,yb,ids)\n",
    "batches_test = clean_data(input_data_t,yb_t,ids_t, test=True) #Doesn't delete data points (only filters features\\\n",
    "\n",
    " #####################################################\n",
    "\n",
    "\n",
    "if (submission):\n",
    "    y_pred_sub = np.ones(len(ids_t))\n",
    "else :\n",
    "    score = 0;\n",
    "\n",
    "i = 0;\n",
    "for [tx, y, ids],[tx_test,y_test,ids_test] in zip(batches,batches_test) :\n",
    "    \n",
    "    print(\"------ Computing weights for batch {} -------\\n\".format(i))\n",
    "    \n",
    "             #### Feature Visualization (uncomment to test) ####\n",
    "        \n",
    "    # features = np.array([1,4,5]) # Features to compare\n",
    "    # visualize_features(tx0,y0,features,'Feature_comparision')\n",
    "    \n",
    "    if (not(submission)) : # We overwrite the test data\n",
    "        tx_train, y_train, tx_test, y_test, ids_train, ids_test = split_data(tx, y, ids, train_ratio, seed=1)\n",
    "    else :\n",
    "        y_train = y\n",
    "        tx_train = tx\n",
    "        ids_train = ids\n",
    "    \n",
    "        \n",
    "    tx_poly_train = build_poly_f(tx_train, degree)\n",
    "    \n",
    "    initial_w = np.zeros(tx_poly_train.shape[1])\n",
    "    \n",
    "    _, w = logistic_regression(y_train, tx_poly_train, initial_w, max_iters, gamma)\n",
    "    w = w[-1]\n",
    "    \n",
    "    tx_poly_test = build_poly_f(tx_test, degree)\n",
    "    \n",
    "    print(\"Predicting labels ...\")\n",
    "    \n",
    "    y_pred = predict_labels(w,tx_poly_test,logistic_reg = True)\n",
    "    \n",
    "    if (submission):\n",
    "        y_pred_sub[ids_test-ids_t[0]] = y_pred\n",
    "    else :\n",
    "        score_aux = find_score(y_pred,y_test)\n",
    "        score += score_aux/4.\n",
    "        \n",
    "        print(\"Score for batch {} = {} \\n\".format(i,score_aux))\n",
    "\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "if (submission):\n",
    "    y_pred_sub = y_pred_sub*2 - 1     \n",
    "    create_csv_submission(ids_t, y_pred_sub, 'submission.csv')\n",
    "else :\n",
    "    print(\"Final score = {} \\n\".format(score))\n",
    "    \n",
    "print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
